{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://stackoverflow.com/questions/40994583/how-to-implement-tensorflows-next-batch-for-own-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.contrib.keras.datasets.cifar10.load_data()\n",
    "\n",
    "X_train = (X_train/255.0).mean(axis=3).reshape(-1, 32*32)\n",
    "X_test = (X_test/255.0).mean(axis=3).reshape(-1, 32*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(50000, 1024)\n",
      "[[6]\n",
      " [9]\n",
      " [9]\n",
      " ..., \n",
      " [9]\n",
      " [1]\n",
      " [1]]\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train.shape)\n",
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.eye(10)[y_train.reshape(-1)]\n",
    "y_test = np.eye(10)[y_test.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "    with tf.name_scope(name):\n",
    "        with tf.variable_scope(\"vs\"):\n",
    "            w = tf.get_variable(initializer=tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"{}_W\".format(name))\n",
    "            b = tf.get_variable(initializer=tf.constant(0.1, shape=[size_out]), name=\"{}_B\".format(name))\n",
    "            conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "            act = tf.nn.relu(conv + b)\n",
    "\n",
    "            print(w.name)\n",
    "            \n",
    "            tf.summary.histogram(\"weights\", w)\n",
    "            tf.summary.histogram(\"biases\", b)\n",
    "            tf.summary.histogram(\"activations\", act)\n",
    "\n",
    "            return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "        act = tf.matmul(input, w) + b\n",
    "        \n",
    "        tf.summary.histogram(\"weights\", w)\n",
    "        tf.summary.histogram(\"biases\", b)\n",
    "        tf.summary.histogram(\"activations\", act)\n",
    "\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropout_layer(input, keep_prob, name=\"dropout\"):\n",
    "    with tf.name_scope(name):\n",
    "        return tf.nn.dropout(input, keep_prob)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_image_tensor(weights):\n",
    "    ''' weights shape = (5, 5, 1, 32)\n",
    "    '''\n",
    "    weights = tf.reshape(weights, shape=(-1, 5, 5, 1))\n",
    "    \n",
    "    # scale weights to [0 255] and convert to uint8\n",
    "    x_min = tf.reduce_min(weights)\n",
    "    x_max = tf.reduce_max(weights)\n",
    "    weights_0_to_1 = (weights - x_min) / (x_max - x_min)\n",
    "\n",
    "    # Images that are represented using floating point values are expected to have values in the range [0,1). \n",
    "    # This op converts between data types, scaling the values appropriately before casting.\n",
    "    weights_0_to_255_uint8 = tf.image.convert_image_dtype(weights_0_to_1, dtype=tf.uint8)\n",
    "    \n",
    "    return weights_0_to_255_uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_images(ndarr):\n",
    "    ndarr = ndarr.squeeze()\n",
    "    \n",
    "    cols = 16\n",
    "    rows = ndarr.shape[0] // cols\n",
    "\n",
    "    print(\"cols = {}, rows = {}\".format(cols, rows))\n",
    "    fig, axes = plt.subplots(figsize=(30, 4), nrows=rows, ncols=cols, sharex=True, sharey=True)\n",
    "\n",
    "    axes = np.hstack(axes)\n",
    "    for sample, ax in zip(ndarr, axes):\n",
    "        ax.imshow(sample, cmap='Greys_r')\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)    \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, X, y):\n",
    "        self._index_in_epoch = 0\n",
    "        self._epochs_completed = 0\n",
    "        self._X = X\n",
    "        self._y = y\n",
    "        self._num_examples = X.shape[0]\n",
    "\n",
    "    @property\n",
    "    def X(self):\n",
    "        return self._X\n",
    "\n",
    "    @property\n",
    "    def y(self):\n",
    "        return self._y\n",
    "    \n",
    "    def next_batch(self, batch_size, shuffle=True):\n",
    "        start = self._index_in_epoch\n",
    "        \n",
    "        if start == 0 and self._epochs_completed == 0:\n",
    "            idx = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "            np.random.shuffle(idx)  # shuffle indexe\n",
    "            self._X = self.X[idx]  # get list of `num` random samples\n",
    "            self._y = self.y[idx]  # get list of `num` random samples\n",
    "\n",
    "        # go to the next batch\n",
    "        if start + batch_size > self._num_examples:\n",
    "            self._epochs_completed += 1\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            X_rest_part = self.X[start : self._num_examples]\n",
    "            y_rest_part = self.y[start : self._num_examples]\n",
    "            \n",
    "            idx0 = np.arange(0, self._num_examples)  # get all possible indexes\n",
    "            np.random.shuffle(idx0)  # shuffle indexes\n",
    "            self._X = self.X[idx0]  # get list of `num` random samples\n",
    "            self._y = self.y[idx0]  # get list of `num` random samples\n",
    "\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples #avoid the case where the #sample != integar times of batch_size\n",
    "            end =  self._index_in_epoch  \n",
    "            X_new_part =  self._X[start:end]  \n",
    "            y_new_part =  self._y[start:end]  \n",
    "            \n",
    "            return np.concatenate((X_rest_part, X_new_part), axis=0), np.concatenate((y_rest_part, y_new_part), axis=0)  \n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            \n",
    "            return self._X[start:end], self._y[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 3 4]\n",
      "[0 3 4]\n",
      "[1 2 2]\n",
      "[1 2 2]\n",
      "[4 3 0]\n",
      "[4 3 0]\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(np.arange(0, 5), np.arange(0, 5))\n",
    "for i in range(3):\n",
    "    X, y = dataset.next_batch(3)\n",
    "    print(X)    \n",
    "    print(y)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs/conv1_W:0\n",
      "vs/conv2_W:0\n",
      "step 0, training accuracy 0.06\n",
      "(5, 5, 1, 32)\n",
      "(32, 5, 5, 1)\n",
      "cols = 16, rows = 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABp8AAADuCAYAAADP0B/HAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3WuQloV5N/BrOYNgoIBVUVmJDliMWiGRsVqr0Vg8ICYZ\nLVSJxtHUmGiN9ZCQsZIYdQzxQKJtPGREqzKmRg3RRKImKip1oKRF1MYIiqCCHNfl7PK8H5j3W98M\n9LpI93nz+31+5r//3Wvvw3NfPEtLo9EIAAAAAAAAqNDlf7sAAAAAAAAA//+wfAIAAAAAAKCM5RMA\nAAAAAABlLJ8AAAAAAAAoY/kEAAAAAABAGcsnAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAA\nAAAAAJTptjMvHjRoUKO1tXUXVWHevHkrG43G4EyGGe165tT5Vcwowpx2NXNqDs55nZ9jqTmYU3Mw\np+bg2tT5OZaagzk1B+e85mBOnZ9zXnMwp+awo3PaqeVTa2trzJ0793/eit+rpaXl7WyGGe165tT5\nVcwowpx2NXNqDs55nZ9jqTmYU3Mwp+bg2tT5OZaagzk1B+e85mBOnZ9zXnMwp+awo3PyZ/cAAAAA\nAAAoY/kEAAAAAABAmZ36s3tLly6NK664Iv1Fv/a1r6UzIiIuvPDCdMYee+xR0CRi5cqV6Yz+/fuP\nymasWrUq7rvvvnSXSy65JJ0RETF06NB0xvz58wuaREyYMKEkp8LWrVvjvffeS+eMGzeuoE3NMdm9\ne/eCJhG33357OqNfv37pYykior29PWbPnp3OGTt2bEGbiG9+85vpjKOPPrqgScTNN9+czhgwYEDJ\nnN555524+OKL0zl///d/X9Am4tFHH01nvPLKKwVNIq699tp0xiGHHJKe0+bNm2PRokXpLvvvv386\nIyLi+eefT2cceOCBBU0i1q1bl84YOXJkybHU1tYWTz75ZDrnuuuuK2gTsddee6UzWlpaCppE7L77\n7umMQYMGlcxp8+bNsXjx4nROr169CtpETJ8+PZ3x9a9/vaBJxDnnnJPOGDhwYMmcPvjgg/inf/qn\ndE5HR0dBm4iNGzemM15++eWCJhEnnnhiOmPo0KEl16Y33ngj3eUzn/lMOiMi4vOf/3w649hjjy1o\nEnHqqadWxJQcS9u2bYv29vZ0zoYNGwra1LxPHjlyZEGTiC984QvpjE984hMlc1q+fHnccsst6ZzB\ng9P/xUdEbL+nyaq6H694z37ggQeWzKlC1XvbqVOnpjO++93vFjSpueessnHjxli4cGE6p2fPngVt\nIq666qp0xuWXX17QpOYZcO/evUuOpVWrVsU999yTzvnRj36ULxMRzzzzTDpj/fr1BU2i5H3/QQcd\nVPasqOK6XfHzjYg47LDD0hnnn39+QZOa6+QBBxywQ3PyyScAAAAAAADKWD4BAAAAAABQxvIJAAAA\nAACAMpZPAAAAAAAAlLF8AgAAAAAAoIzlEwAAAAAAAGUsnwAAAAAAAChj+QQAAAAAAEAZyycAAAAA\nAADKWD4BAAAAAABQxvIJAAAAAACAMpZPAAAAAAAAlLF8AgAAAAAAoIzlEwAAAAAAAGUsnwAAAAAA\nAChj+QQAAAAAAEAZyycAAAAAAADKdNuZF3ft2jU+9rGPpb/opZdems6oct9995XkbNiwIZ0xevTo\ndMamTZvi1VdfTef88Ic/TGdERIwcOTKdMWXKlIImEePGjSvJmTFjRjrj7bffjgsuuCCd85nPfCad\nERHx8MMPpzM2b95c0CTiH/7hH9IZl1xySUGTiJUrV8aPfvSjdM7RRx9d0CZi4sSJ6Yxp06YVNIk4\n6KCD0hkvvPBCQZOItWvXxuOPP57OOeOMMwraRBx++OHpjOOOO66gScSECRPSGYsWLUpnrFq1KqZP\nn57O+epXv5rOiIg45phj0hkV14KIiFmzZqUz3n///YImEVu3bo0VK1akc5599tmCNhEtLS3pjJNP\nPrmgScRjjz2Wzti0aVNBk+3Xpor7tKr7ojfffDOdMX/+/IImEVu2bElnzJkzp6BJxO67715yn1Zx\nHEREPP/88+mMJUuWFDSJaG9vT2d0dHSkM9asWROPPvpoOmfEiBHpjIiIww47LJ1xxx13FDSJOPfc\nc9MZFefNiIhly5bF1Vdfnc6peI8cETFs2LB0xle+8pWCJhH9+/dPZ/To0aOgScSAAQPi9NNPT+eM\nGjWqoE3ERRddlM6ouL5FRLz88svpjPXr16cz1q1bF0888UQ6p+p+/Omnn05nHHjggQVNap6HVGlv\nb4/nnnsunXPhhRcWtIk45ZRT0hlVz4qq7hcrrF27Nn72s5+lc77//e8XtImS99qvvfZaQZOIPn36\npDPWrl1b0CRi3333jVtvvTWdM3To0II2Eccff3w6o+p+Zvz48emMHZ21Tz4BAAAAAABQxvIJAAAA\nAACAMpZPAAAAAAAAlLF8AgAAAAAAoIzlEwAAAAAAAGUsnwAAAAAAAChj+QQAAAAAAEAZyycAAAAA\nAADKWD4BAAAAAABQxvIJAAAAAACAMpZPAAAAAAAAlLF8AgAAAAAAoIzlEwAAAAAAAGUsnwAAAAAA\nAChj+QQAAAAAAEAZyycAAAAAAADKWD4BAAAAAABQptvOvHjTpk2xcOHC9Be99tpr0xkRESeccEI6\n41/+5V8Kmmz/2WQ1Go10RkdHR7S3t6dzZs2alc6IiPjd736XznjttdcKmkTMmDGjJKfCXnvtFZMn\nT07njBkzpqBNxKmnnprOOP300wuaRDzyyCPpjLVr1xY0iWhrays5FqZNm1bQJuLFF19MZ1TN6f77\n709nfPTRRwVNIoYPHx4zZ85M5/Tq1augTUTXrl3TGYsXLy5oUnONO/nkk9MZbW1t8dRTT6VzPv3p\nT6czIiI+97nPpTOOOOKIgiYRe+yxRzpj9uzZBU0iBgwYEOPHjy/JqTBq1Kh0xtVXX13QJOLZZ59N\nZ7S0tBQ0idhtt93iyCOPTOdUnMcjIj75yU+mM+bNm1fQJGLBggXpjNWrVxc0iXjllVfigAMOSOdU\nvD+IiBg8eHA648033yxoEvHkk0+mM9ra2tIZy5YtiyuuuCKds3nz5nRGRMSkSZPSGbfffntBk5r7\n8ar3k3369IlDDz00nVPxficiol+/fumMm2++uaDJ9nvgrKpz3qJFi2LixInpnIrvKSJiyJAh6Yxf\n/OIXBU1q7iEq7umXLFkSF154YTrnoYceSmdE1ByT1113XUGTupyxY8emM9atWxePP/54OueQQw5J\nZ0REyT3nfvvtV9Ck5pneN77xjYImER9++GE8/fTT6ZyKZ8kRNc95xo0bV9Ak4i//8i/TGU888URB\nk4j169fHnDlz0jkDBw4saBPx61//Op0xevTofJE/MJ98AgAAAAAAoIzlEwAAAAAAAGUsnwAAAAAA\nAChj+QQAAAAAAEAZyycAAAAAAADKWD4BAAAAAABQxvIJAAAAAACAMpZPAAAAAAAAlLF8AgAAAAAA\noIzlEwAAAAAAAGUsnwAAAAAAAChj+QQAAAAAAEAZyycAAAAAAADKWD4BAAAAAABQxvIJAAAAAACA\nMpZPAAAAAAAAlOm2My9ubW2Ne++9N/1Fr7/++nRGRESvXr3SGbfeemtBk4jf/OY36Yz33nsvnTFg\nwID47Gc/m84ZNmxYOiMiok+fPumMSZMmFTSJ+PKXv1ySc/HFF6czPvzww3j++efTObfffns6IyJi\n8uTJ6YxTTjmloEnE3Xffnc741a9+VdAkYvjw4fHTn/40nTNnzpyCNhE33nhjOqPiXBUR0Wg00hn/\n9m//VtAkYsOGDTFv3rx0zrHHHlvQZvt5OKviehAR0a9fv3RG165d0xl77rlnXHnllemcmTNnpjMi\nIlavXp3O2HvvvQuaRGzatCmd0b1794ImERs3boxXX301nfPaa68VtIl44IEH0hkPPfRQQZOIgw8+\nOJ2xYMGCgiYRHR0dsWbNmnROxTUlIuL8889PZyxevLigScS1116bzvj5z39e0GT7teD4449P57z4\n4osFbSLOPffcdMaUKVMKmkScc8456YzTTjstnTFgwIA48cQT0znt7e3pjIiIcePGpTPefPPNgiYR\nn/rUp9IZu+22W0GT7fecW7ZsSecceeSRBW1qnkFcc801+SJR8z317du3oElE//79Y/z48emcE044\noaBNxD777JPOeOyxxwqa1Ny/Vty7RkR067ZTjwD/W2PGjCloEnHnnXemM+bPn1/QpOb3pUp7e3vJ\n84PBgwcXtIn47W9/m87Yc889C5pEtLW1pTM6OjoKmmx/Zjpt2rR0ztixYwvaRMlz4Msuu6ygScR5\n552Xzvjggw8KmkRs3rw53nrrrXRO1bnmmWeeSWc8+uijBU1qnn/t6M/WJ58AAAAAAAAoY/kEAAAA\nAABAGcsnAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAA\nAABlLJ8AAAAAAAAoY/kEAAAAAABAGcsnAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAA\nAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8AAAAAAAAo021nXvzee+/Ft7/97fQXHTVqVDojIuLHP/5x\nOuO5554raBJx+eWXpzMefPDBdMa2bdti06ZN6ZzW1tZ0RkTEHXfcUZJT4bTTTivJufjii9MZe+yx\nR/zd3/1dOqd79+7pjIiIr371q+mMM888s6BJxPjx40tyKqxduzYee+yxdM5PfvKTgjYRZ5xxRjrj\nxBNPLGgSceedd6YzVq5cWdAk4mMf+1iccsop6ZxHHnmkoE3EX//1X6czxowZU9AkYsOGDSU5FRqN\nRjrju9/9bkGTiPvuuy+dMWfOnIImEZ/61KfSGT179ixoErF58+b43e9+l85Zu3ZtQZuIv/iLv0hn\nPPPMMwVNIvbbb790xn/9138VNIkYOHBgfOELX0jnbNu2raBNxN/8zd+kM84///yCJhELFixIZ1Sd\nN7t06RJ9+vRJ5zz11FMFbSIGDx6czpg5c2ZBk4i/+qu/Smd06ZL/N5TDhg0ref/1+uuvpzMiIu66\n6650xvr16wuaRBxxxBHpjNWrVxc0iejbt28cc8wx6ZwXXnihoE1ER0dHOqPiXjGi5j1cxbEUEbFs\n2bK44oor0jmzZ88uaFPz3v/GG28saBJx3HHHpTMq7meGDx8ejz/+eDpn8uTJ6YyImnNe1bPFqmcZ\nZ511VjpjxIgR8dBDD6Vz/vmf/zmdERFx8sknpzM2b95c0CTiqKOOSmf07du3oElEr1694uCDD07n\n3HTTTQVtIpYuXZrOePrppwuaRKxYsSKdcdtttxU02f6+tOI5T8X+ISLi/vvvT2dMnTq1oEnNe/at\nW7fu0Ot88gkAAAAAAIAylk8AAAAAAACUsXwCAAAAAACgjOUTAAAAAAAAZSyfAAAAAAAAKGP5BAAA\nAAAAQBnLJwAAAAAAAMpYPgEAAAAAAFDG8gkAAAAAAIAylk8AAAAAAACUsXwCAAAAAACgjOUTAAAA\nAAAAZSyfAAAAAAAAKGP5BAAAAAAAQBnLJwAAAAAAAMpYPgEAAAAAAFDG8gkAAAAAAIAyLY1GY4df\nPHr06MbcuXN3YZ0/bi0tLfMajcboTIYZ7Xrm1PlVzCjCnHY1c2oOznmdn2OpOZhTczCn5uDa1Pk5\nlpqDOTUH57zmYE6dn3NeczCn5rCjc/LJJwAAAAAAAMpYPgEAAAAAAFDG8gkAAAAAAIAylk8AAAAA\nAACUsXwCAAAAAACgTEuj0djxF7e0fBARb++6On/0hjYajcGZADP6gzCnzi89owhz+gMwp+bgnNf5\nOZaagzk1B3NqDq5NnZ9jqTmYU3NwzmsO5tT5Oec1B3NqDjs0p51aPgEAAAAAAMDv48/uAQAAAAAA\nUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8AAAAAAAAoY/kEAAAAAABA\nGcsnAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABl\nLJ8AAAAAAAAoY/kEAAAAAABAGcsnAAAAAAAAylg+AQAAAAAAUKbbzrx40KBBjdbW1l1UhXnz5q1s\nNBqDMxlmtOuZU+dXMaMIc9rVzKk5OOd1fo6l5mBOzcGcmoNrU+fnWGoO5tQcnPOagzl1fs55zcGc\nmsOOzmmnlk+tra0xd+7c/3krfq+Wlpa3sxlmtOuZU+dXMaMIc9rVzKk5OOd1fo6l5mBOzcGcmoNr\nU+fnWGoO5tQcnPOagzl1fs55zcGcmsOOzsmf3QMAAAAAAKCM5RMAAAAAAABlLJ8AAAAAAAAos1P/\n59PKlSvj7rvvTn/RBx54IJ0REfGd73wnnfHEE08UNIno169fOmPIkCGjshlbt26NZcuWpbu88847\n6YyIiEsvvTSdce211xY0iTjmmGNKciq88cYbcdJJJ6VzLrvssoI2EZMmTUpnXH/99QVNtv8OZw0d\nOjR9LEVEvP7663HUUUelcyp+vhERL7/8cjrjBz/4QUGTiLfeeiudMXLkyJI5rVy5Mu666650zhtv\nvFHQJuL9999PZ+y1114FTSKmTJmSzjj88MPTc5o3b15079493WXGjBnpjIiImTNnpjPGjx9f0CTi\nyiuvTGf07Nmz5FjauHFjLFiwIJ3zs5/9rKDN9nNwVpcuNf/O6rzzzktnDB8+vGROy5Yti69//evp\nnOeee66gTcSXvvSldMZ7771X0KRm3hX34xERa9asiYcffjid89vf/ragTcTuu++ezjj33HMLmtTc\nk/fp0yc9p3feeafkvcq4cePSGRERxx57bDpj2rRpBU0ijjzyyHTGQQcdVHIsbd68ORYvXpzOueii\niwraROyzzz6dIiMi4sQTT0xnjBgxomRO69atK7n+V/1szj777HRGxXkzImLixInpjH333Tc9p+XL\nl8dNN92U7jJnzpx0RkTEWWedlc449NBDC5pEp/o/Ydrb2+P5559P5yxcuLCgTcSECRPSGWvWrClo\nEjFs2LCKmJJz3oIFC+LjH/94OmfRokUFbSKmTp2azvjggw8Kmmx/PpM1aNCgkjmtXbs2HnvssXTO\npk2bCtpEjBw5Mp1xww03FDSJuP/++ytidmhOPvkEAAAAAABAGcsnAAAAAAAAylg+AQAAAAAAUMby\nCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8AAAAAAAAoY/kEAAAAAABAGcsn\nAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8A\nAAAAAAAoY/kEAAAAAABAmW478+KuXbtG//7901/0zDPPTGdERCxYsCCd8bWvfa2gScRtt92Wzmg0\nGumMjo6OaGtrS+e88cYb6YyImu/pySefLGgSsffee5fkVGhra4uf//zn6ZyePXsWtIn48pe/nM44\n6aSTCppEXHTRRemMimPg/+ro6EhnzJ49u6BJxGc/+9l0xquvvlrQJOKCCy5IZyxevLigSUTv3r3j\n0EMPTeeMGTOmoE1Et247dWn9b82aNaugScRvfvObdMaGDRvSGd27d48999wznXP33XenMyKi5Px7\nxhlnFDSJWL9+fTpj27ZtBU0i3n333ZgyZUo6Z9myZQVtIu655550RsU5PCJi//33T2f06dOnoMn2\n+5lrrrkmnVORERGxdevWdMY555yTLxIR8+fPT2dUzalnz57R2tqazvnc5z6XLxMRffv2TWdMmjSp\noEnEhAkT0hk333xzOqN79+6xxx57pHOWL1+ezoiIuPzyy9MZw4cPL2gSccABB6Qzqt6nrFmzJmbM\nmJHOqbpW9u7du1NkRNT8zixdurSgyfafb8U9zaOPPlrQJuKWW25JZ6xYsaKgScSQIUPSGRXXpra2\ntnjqqafSOX/6p3+azoiI+OQnP5nOeP311wuaRCxZsqQkp0Kj0Si5txo1alRBm5rj4MEHHyxoEvHr\nX/86nVHxHCMiYsuWLbFo0aJ0zq233lrQJuKuu+5KZ1xyySUFTSK+9a1vpTMq7ukjtl+b2tvb0zlV\nz2eOPvrodMbIkSMLmtQ8K5o4ceIOvc4nnwAAAAAAAChj+QQAAAAAAEAZyycAAAAAAADKWD4BAAAA\nAABQxvIJAAAAAACAMpZPAAAAAAAAlLF8AgAAAAAAoIzlEwAAAAAAAGUsnwAAAAAAAChj+QQAAAAA\nAEAZyycAAAAAAADKWD4BAAAAAABQxvIJAAAAAACAMpZPAAAAAAAAlLF8AgAAAAAAoIzlEwAAAAAA\nAGUsnwAAAAAAACjTbWde/NFHH8WqVavSX/SQQw5JZ0REDBw4sCSnwpAhQ9IZPXr0SGds27Yt1q9f\nn845++yz0xkREW+++WY6Y9myZQVNIiZNmlSSU2HUqFExd+7cdM4JJ5xQ0CbiiCOOSGe8++67BU0i\n1q1bl87o6OgoaBKxfv36mDNnTjrn4osvLmgTMWXKlHTGn/zJnxQ0ifjEJz6RznjrrbfyRSKiS5cu\nJefPgw8+uKBNxG233ZbOuOmmmwqaRBx55JHpjBUrVqQzBg4cWHJd2bZtWzojImLNmjXpjI9//OMF\nTSKmTZuWzrjiiisKmkQMGzYsZsyYkc4ZPXp0QZuIJUuWpDN69+5d0CTiz/7sz9IZXbrU/JuvpUuX\nxlVXXZXO2bJlS0GbiE9/+tPpjJdeeqmgSc21qWfPngVNIt5555249NJL0zmzZs0qaFNzbfrOd75T\n0CSitbU1nVFxPG3btq3kOBg0aFA6IyLisMMOS2fMnDmzoEnN9Xb16tUFTSLa29tL7scrjoGIiFde\neSWd8frrrxc0ibjvvvvSGaeeempBk4gBAwbEmWeemc558sknC9pELF++PJ1x0kknFTSpORa6d++e\nzmhra4tf/vKX6Zyq9/3f/va30xnnnXdeQZOI2bNnl+RU6NGjR8l1sl+/fvkyESX3MnfeeWdBk4gH\nH3wwnbFp06aCJhEHHXRQ3Hvvvemcww8/vKBNzTOnCRMmFDTpXM9eq46nqnPE9OnT0xnjx48vaFJz\nXK5cuXKHXueTTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8AAAAAAAAoY/kEAAAAAABAGcsn\nAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8A\nAAAAAAAoY/kEAAAAAABAGcsnAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDLddubFgwcPjgsuuCD9\nRV944YV0RkTE5Zdfns4488wzC5pEvP/+++mMrVu3lvS48cYb0zkzZsxIZ0RE/OM//mM6Y8OGDQVN\nIq6//vqSnLlz56YzVq1aFdOnT0/nfOlLX0pnRETsu+++6YwuXWp22XvttVc6o3v37gVNIgYMGBAn\nnHBCOmfp0qUFbSLmz5+fzqj62axevTqd8R//8R8FTSIajUZs27YtnTN27NiCNhEPPPBAOuOXv/xl\nQZOIo446Kp1Rcc1uNBqxadOmdE7VOa9Hjx7pjOHDhxc0ifje976Xzli3bl1Bk4h///d/LzlHVJzH\nIyKOOeaYdMYdd9xR0CSib9++6Yyq+5m+ffuWHNsVP9+IiPb29nTG1VdfXdAk4qqrrkpnrF+/vqBJ\nxH777Rff//730zm9e/cuaFPz+3f88ccXNKmZ0w9/+MN0Rv/+/eO0005L5xx66KHpjIiIL37xi+mM\niu8nouY93PLlywuabH+fUnGt/OY3v1nQJmK33XZLZ1R8PxERc+bMSWdU3J9FRMybNy9aWlrSOVOn\nTi1oE/HRRx+lM6req6xduzadsXHjxnTGiBEj4t57703nvPTSS+mMiIgxY8akM6rOv6NHjy7J+clP\nfpLO6NGjR+y9997pnIcffjidERExZMiQdMaPf/zjgiYRxx13XDrjlltuKWgS8eGHH8azzz6bzlm4\ncGFBm5r3KpdeemlBk4gbbrghnVHxjD1i+3PKinvpp556qqBNlBzbkydPLmgScd1116UzdvQY8Mkn\nAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8A\nAAAAAAAoY/kEAAAAAABAGcsnAAAAAAAAylg+AQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIA\nAAAAAKCM5RMAAAAAAABlLJ8AAAAAAAAoY/kEAAAAAABAGcsnAAAAAAAAynTbmRevWLEibrvttvQX\n/cpXvpLOiIh45JFH0hmTJ08uaBLxrW99K53Rs2fPgiY1LrvsspKc4447Lp0xbty4giYRP/3pT0ty\nKrz77rtxzTXXpHNeeumlfJmI2LhxYzrjP//zPwuaRLS2tqYzevTokS8SEXvuuWdceeWV6ZxFixYV\ntIm44YYb0hlf/OIXC5pEtLS0lORUWL9+fcyZMyed84tf/KKgTc25vGLWEVHyc+nSJf/vVNatWxez\nZs1K5/Tv3z+dERElx3XFeTMiYvz48emMX/3qVwVNInbbbbc47LDD0jlV57y77747nfH5z3++oEnE\nkiVL0hmNRqOgyfafb8X3dfXVVxe0iZgyZUo64/jjjy9oEjFx4sR0xk033VTQJGLVqlXxwAMPpHPm\nzZtX0Cbi+uuvT2dMnTq1oEnE7rvvns7o2rVrOmPr1q2xdOnSdM6f//mfpzMiIhYuXJjOGDt2bEGT\niNNPPz2d8eCDDxY0idiyZUu8/fbb6ZwZM2YUtKk5l2/atKmgScT06dPTGatWrSpoEjFixIi45557\n0jkV54eIiIceeiidMXDgwIImEYsXL05ndHR0pDO6dOkSvXr1Sud067ZTjxH/n1599dV0xl133VXQ\nJOIb3/hGSU6F9vb2ePHFF9M5f/u3f1vQJuKss85KZ1Tdy1Qck1W/vz169Ih99tknnXP22WcXtIn4\nwQ9+kM7Ydkm6AAAB/UlEQVSoeg9X8Ty54nl/xPbzXp8+fdI5+++/f0GbmucQ//qv/1rQJEqeSe/o\nPZFPPgEAAAAAAFDG8gkAAAAAAIAylk8AAAAAAACUsXwCAAAAAACgjOUTAAAAAAAAZSyfAAAAAAAA\nKGP5BAAAAAAAQBnLJwAAAAAAAMpYPgEAAAAAAFDG8gkAAAAAAIAylk8AAAAAAACUsXwCAAAAAACg\njOUTAAAAAAAAZSyfAAAAAAAAKGP5BAAAAAAAQBnLJwAAAAAAAMpYPgEAAAAAAFCmpdFo7PCLR48e\n3Zg7d+4urPPHraWlZV6j0RidyTCjXc+cOr+KGUWY065mTs3BOa/zcyw1B3NqDubUHFybOj/HUnMw\np+bgnNcczKnzc85rDubUHHZ0Tj75BAAAAAAAQBnLJwAAAAAAAMpYPgEAAAAAAFDG8gkAAAAAAIAy\nLY1GY8df3NLyQUS8vevq/NEb2mg0BmcCzOgPwpw6v/SMIszpD8CcmoNzXufnWGoO5tQczKk5uDZ1\nfo6l5mBOzcE5rzmYU+fnnNcczKk57NCcdmr5BAAAAAAAAL+PP7sHAAAAAABAGcsnAAAAAAAAylg+\nAQAAAAAAUMbyCQAAAAAAgDKWTwAAAAAAAJSxfAIAAAAAAKCM5RMAAAAAAABlLJ8AAAAAAAAoY/kE\nAAAAAABAmf8DSRfkzwRgofEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea203b0898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 1024], name=\"x\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name=\"labels\")\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 32, 32, 1])\n",
    "\n",
    "tf.summary.image('input', x_image, 3)\n",
    "\n",
    "conv1 = conv_layer(x_image, 1, 32, name=\"conv1\")\n",
    "conv2 = conv_layer(conv1, 32, 64, name=\"conv2\")\n",
    "\n",
    "flattened = tf.reshape(conv2, [-1, 8 * 8 * 64])\n",
    "dropped = dropout_layer(flattened, keep_prob)\n",
    "logits = fc_layer(dropped, 8 * 8 * 64, 10, \"fc\")\n",
    "\n",
    "with tf.name_scope(\"xent\"):\n",
    "    xent = tf.reduce_mean(\n",
    "               tf.nn.softmax_cross_entropy_with_logits(\n",
    "               logits=logits, labels=y), name=\"xent\")\n",
    "    \n",
    "    tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)    \n",
    "    \n",
    "summ = tf.summary.merge_all()\n",
    "    \n",
    "sess.run(tf.global_variables_initializer())\n",
    "writer = tf.summary.FileWriter('/tmp/tb/cifar10_cnn')\n",
    "writer.add_graph(sess.graph)\n",
    "\n",
    "dataset = Dataset(X_train, y_train)\n",
    "\n",
    "for i in range(20001):\n",
    "    batch = dataset.next_batch(100)\n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        [training_accuracy, s] = sess.run([accuracy, summ], feed_dict={x: batch[0], \n",
    "                                                                       y: batch[1],\n",
    "                                                                       keep_prob: 1.0})\n",
    "    \n",
    "        writer.add_summary(s, i)\n",
    "\n",
    "        print('step %d, training accuracy %g' % (i, training_accuracy))\n",
    "        \n",
    "        # show\n",
    "        with tf.variable_scope(\"vs\", reuse=True):\n",
    "            weights = tf.get_variable(\"conv1_W\")\n",
    "            bias = tf.get_variable(\"conv1_B\")\n",
    "            w = weights + bias\n",
    "            print(w.shape)\n",
    "            img_tensor = to_image_tensor(w)\n",
    "            print(img_tensor.shape)\n",
    "            data = img_tensor.eval(session=sess).squeeze()\n",
    "            show_images(data)            \n",
    "        \n",
    "    sess.run(train_step, feed_dict={x: batch[0], \n",
    "                                    y: batch[1],\n",
    "                                    keep_prob: 0.5})\n",
    "\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
