{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "https://stackoverflow.com/questions/33759623/tensorflow-how-to-save-restore-a-model\n",
    "\n",
    "http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Graph\n",
    "\n",
    "> This is a protocol buffer which saves the complete Tensorflow graph; i.e. all variables, operations, collections etc. \n",
    "\n",
    "> This file has **.meta** extension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint file\n",
    "\n",
    "> This is a binary file which contains all the values of the weights, biases, gradients and all the other variables saved. \n",
    "\n",
    "> This file has an extension **.ckpt**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_save_path = '/tmp/my_tf_test_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow variables are only alive in session, you have to save them in session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "w1 = tf.Variable(tf.truncated_normal(shape=[10]), name='w1')\n",
    "w2 = tf.Variable(tf.truncated_normal(shape=[20]), name='w2')\n",
    "\n",
    "tf.add_to_collection('vars', w1)\n",
    "tf.add_to_collection('vars', w2)\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, model_save_path)   \n",
    "    \n",
    "    # Training...\n",
    "    # subsequent trainings meta graph is not updated so you don't need to resave it again\n",
    "    # set write_meta_graph=False\n",
    "    # saver.save(sess, model_save_path, global_step=step, write_meta_graph=False)\n",
    "    \n",
    "    # other parameters to tune\n",
    "    # saver.save(sess, model_save_path, global_step=step, \n",
    "    #            write_meta_graph=False,\n",
    "    #            max_to_keep=4,\n",
    "    #            keep_checkpoint_every_n_hours=2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root    4 Sep  1 08:18 /tmp/my_test_model-1000.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root  120 Sep  1 08:18 /tmp/my_test_model-1000.index\r\n",
      "-rw-r--r-- 1 root root 2790 Sep  1 08:18 /tmp/my_test_model-1000.meta\r\n",
      "-rw-r--r-- 1 root root    4 Sep  1 08:21 /tmp/my_tf_test_model-1000.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root  120 Sep  1 08:21 /tmp/my_tf_test_model-1000.index\r\n",
      "-rw-r--r-- 1 root root 2790 Sep  1 08:21 /tmp/my_tf_test_model-1000.meta\r\n",
      "-rw-r--r-- 1 root root  120 Sep  1 08:23 /tmp/my_tf_test_model.data-00000-of-00001\r\n",
      "-rw-r--r-- 1 root root  143 Sep  1 08:23 /tmp/my_tf_test_model.index\r\n",
      "-rw-r--r-- 1 root root 4817 Sep  1 08:23 /tmp/my_tf_test_model.meta\r\n"
     ]
    }
   ],
   "source": [
    "% ls -al /tmp/my*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save only some variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "w1 = tf.Variable(tf.random_normal(shape=[2]), name='w1')\n",
    "w2 = tf.Variable(tf.random_normal(shape=[5]), name='w2')\n",
    "\n",
    "# only save w1 and w2\n",
    "saver = tf.train.Saver([w1, w2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    saver.save(sess, '/tmp/my_test_model', global_step=1000)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_tf_test_model\n",
      "[-1.43592906  0.49199969  0.3102732   0.70848399 -0.28851402 -0.91920251\n",
      "  0.67731011  1.16958964 -0.35451865 -0.31641874]\n",
      "[ 0.95022619  0.79574502 -0.40759259  0.03828121 -0.47309098 -1.92819595\n",
      "  0.07515428  0.06131484 -0.42148468 -0.19982119  0.59885925 -1.40948188\n",
      " -0.45097643 -0.43091989 -0.51169211 -0.12227061  0.28253883 -1.29828274\n",
      " -0.71952969 -0.20967431]\n",
      "[-1.43592906  0.49199969  0.3102732   0.70848399 -0.28851402 -0.91920251\n",
      "  0.67731011  1.16958964 -0.35451865 -0.31641874]\n",
      "[ 0.95022619  0.79574502 -0.40759259  0.03828121 -0.47309098 -1.92819595\n",
      "  0.07515428  0.06131484 -0.42148468 -0.19982119  0.59885925 -1.40948188\n",
      " -0.45097643 -0.43091989 -0.51169211 -0.12227061  0.28253883 -1.29828274\n",
      " -0.71952969 -0.20967431]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    new_saver = tf.train.import_meta_graph('{}.meta'.format(model_save_path))\n",
    "    new_saver.restore(sess, tf.train.latest_checkpoint(os.path.dirname(model_save_path)))\n",
    "    \n",
    "    all_vars = tf.get_collection('vars')\n",
    "\n",
    "    for v in all_vars:\n",
    "        v_ = sess.run(v)\n",
    "        print(v_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Full Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Graph & Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Prepare to feed input, i.e. feed_dict and placeholders\n",
    "w1 = tf.placeholder(\"float\", name=\"w1\")\n",
    "w2 = tf.placeholder(\"float\", name=\"w2\")\n",
    "b1 = tf.Variable(2.0, name=\"bias\")\n",
    "feed_dict ={w1:4, w2:8}\n",
    "\n",
    "# Define a test operation that we will restore\n",
    "# (w1 + w2) * b1\n",
    "w3 = tf.add(w1, w2)\n",
    "w4 = tf.multiply(w3, b1, name=\"op_to_restore\")\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    # Create a saver object which will save all the variables\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Run the operation by feeding input\n",
    "    print(sess.run(w4, feed_dict))\n",
    "    # Prints 24 which is sum of (w1+w2)*b1 \n",
    "\n",
    "    #Now, save the graph\n",
    "    saver.save(sess, model_save_path, global_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/my_tf_test_model-1000.data-00000-of-00001\r\n",
      "/tmp/my_tf_test_model-1000.index\r\n",
      "/tmp/my_tf_test_model-1000.meta\r\n",
      "/tmp/my_tf_test_model.data-00000-of-00001\r\n",
      "/tmp/my_tf_test_model.index\r\n",
      "/tmp/my_tf_test_model.meta\r\n"
     ]
    }
   ],
   "source": [
    "% ls $model_save_path*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get specific weight or operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w1:0\n",
      "op_to_restore:0\n"
     ]
    }
   ],
   "source": [
    "graph = tf.get_default_graph()\n",
    "\n",
    "# How to access saved variable/Tensor/placeholders \n",
    "w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "print(w1.name)\n",
    "\n",
    "## How to access saved operation\n",
    "op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "print(op_to_restore.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load trained model, feed new data for prediction\n",
    "\n",
    "#### Note the feed_dict's key is the Actural Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_tf_test_model-1000\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #First let's load meta graph and restore weights\n",
    "    saver = tf.train.import_meta_graph('{}-1000.meta'.format(model_save_path))\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(os.path.dirname(model_save_path)))\n",
    "\n",
    "    # Now, let's access and create placeholders variables and\n",
    "    # create feed-dict to feed new data\n",
    "    graph = tf.get_default_graph()\n",
    "    \n",
    "    w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "    w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "    \n",
    "    # new data to feed: predict\n",
    "    feed_dict ={w1:13.0, w2:17.0}\n",
    "\n",
    "    #Now, access the op that you want to run. \n",
    "    op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "    print(sess.run(op_to_restore, feed_dict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Graph, add more Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/my_tf_test_model-1000\n",
      "120.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # First let's load meta graph and restore weights\n",
    "    saver = tf.train.import_meta_graph('{}-1000.meta'.format(model_save_path))\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(os.path.dirname(model_save_path)))\n",
    "\n",
    "    # Now, let's access and create placeholders variables and\n",
    "    # create feed-dict to feed new data\n",
    "    graph = tf.get_default_graph()\n",
    "    w1 = graph.get_tensor_by_name(\"w1:0\")\n",
    "    w2 = graph.get_tensor_by_name(\"w2:0\")\n",
    "    \n",
    "    feed_dict ={w1:13.0, w2:17.0}\n",
    "\n",
    "    # Now, access the op that you want to run. \n",
    "    op_to_restore = graph.get_tensor_by_name(\"op_to_restore:0\")\n",
    "\n",
    "    # Add more to the current graph\n",
    "    add_on_op = tf.multiply(op_to_restore, 2)\n",
    "\n",
    "    print(sess.run(add_on_op, feed_dict))\n",
    "    # This will print 120."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load part of pre-trained Graph and rewire it\n",
    "\n",
    "```Python\n",
    "saver = tf.train.import_meta_graph('vgg.meta')\n",
    "# Access the graph\n",
    "graph = tf.get_default_graph()\n",
    "## Prepare the feed_dict for feeding data for fine-tuning \n",
    "\n",
    "#Access the appropriate output for fine-tuning\n",
    "fc7= graph.get_tensor_by_name('fc7:0')\n",
    "\n",
    "#use this if you only want to change gradients of the last layer\n",
    "fc7 = tf.stop_gradient(fc7) # It's an identity function\n",
    "fc7_shape= fc7.get_shape().as_list()\n",
    "\n",
    "new_outputs = 2\n",
    "weights = tf.Variable(tf.truncated_normal([fc7_shape[3], num_outputs], stddev=0.05))\n",
    "biases = tf.Variable(tf.constant(0.05, shape=[num_outputs]))\n",
    "output = tf.matmul(fc7, weights) + biases\n",
    "pred = tf.nn.softmax(output)\n",
    "\n",
    "# Now, you run this with fine-tuning data in sess.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
